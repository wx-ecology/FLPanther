---
title: "Panther GLMM"
author: "Wenjing Xu"
date: "4/17/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(survival)
library(dplyr)
library(ggplot2)
library(GGally)
library(arm)
#library(MCMCglmm)
#library(plotMCMC)
library(reshape)
#library(parallel)
library(aod)
library(fastDummies)
library(MuMIn)
```

## dataframe prep
```{r data prep}
# reclassify vegetation class
data <- read.csv("Final_Variable_all.csv")
veg.code <- read.csv("VegCombineCode.csv")
# reshape data
data <- data %>% dplyr::left_join(veg.code, by = "CLC_STATE")
data.full <- data %>% filter (!is.na(Fire_Cat))
# reduce to 10 random points for each den 
set.seed(17)
data.0 <- data.full %>% group_by (DenID) %>% filter( Used == 0 ) %>% sample_n(10)
data.1 <- data.full %>% filter( Used == 1 ) 
data <- union (data.1, data.0) %>% arrange (DenID)

# specify factors. Levels order will affect the baseline level in the modeling process
data$DenID <- as.factor(data$DenID)
data$Fire_Cat <- factor(data$Fire_Cat, levels = c("U", "A", "B", "C", "D"))
```

## Examining variables
```{r examining categorical variables, results="hide", include=FALSE}
# investigate vegetation class 
#data %>% filter (Used == "1") %>% group_by(Specific.Class) %>% summarise(used.count = n())
# what to do with Bare soil/clear cut and Exotic plants? -- need to examine neighboring class in maps and maybe reclassify based on that. For now, leave them out. 
#data %>% filter (Used == "1") %>% filter ((Specific.Class == "Bare Soil/Clear Cut") | (Specific.Class == "Exotic Plants")) %>% dplyr::select(DenID)
#data <- data %>% filter ((DenID != "61") & (DenID != "95A"))

# investiage combined class
#data %>% filter (Used == "1") %>% group_by(Combined) %>% summarise(used.count = n())
```




```{r reclass veg class}
data %>% group_by(Combined) %>% summarise(used.count = n())
# get rid of the factors that are ecologically unlikely to be meaningful
# or that likely do not have much explanatory power (drop CatID because not enough replicates for each cat)
# or are obviously correlated (e.g. ave_wet and ave_dry)
# also deleted age because does not really show importance but interfere with the modeling process from previous runs
data <- data %>% dplyr::select(Used, DenID, Fire_Cat, Ave_Wet, Prec_Tree, dist2build, Combined) %>% dplyr::rename(Veg_Class = Combined)
data$Veg_Class <- factor(data$Veg_Class, levels = c("Upland Forest", "Other", "Marsh-Shrub-Swamp", "Prairie-Grassland", "Wetland Forest"))
```

## data exploration

```{r outlier}
op <- par(mfrow = c(3, 1))
dotchart(data$Ave_Wet, main = "Average water height in wet season", group = data$Fire_Cat)
dotchart(data$dist2build, main = "Distance to Building", group = data$Fire_Cat)
dotchart(data$Prec_Tree, main = "Percept Tree", group = data$Fire_Cat)
par(op)
```
Age and dist2build has some outliers at the far end. So do transformation on these two. 

```{r colinearity}
data$L.dist2build <- log10(data$dist2build+1) #since some of the dist is 0
data.L <- data %>% dplyr::select(Used, DenID, Fire_Cat, Ave_Wet, Prec_Tree, L.dist2build, Veg_Class) 

cor(data.L[,c(4:6)]) #does not seem to have strong linear relations
ggpairs(data.L[, c( "Ave_Wet", "Prec_Tree", "L.dist2build")])
```

This plot further confirmed that there are no obvious linear relations. 

```{r categorical variables, include = false}
#The table shows we have a unbalanced dataset in terms of Fire_Cat. In principle, lme4 can deal with unbalanced data sets but the low number of data points in some cells of the design means that it is hard to estimate some of the effects. 
data.L %>% group_by(Fire_Cat) %>% summarise(used.count = n())
par(mfrow = c(1, 2))
ggplot(data.L, aes(x = Fire_Cat, y = DenID)) +
  stat_sum(aes(size = ..n.., group = Fire_Cat, color = factor(Used))) +
  scale_size_area(max_size=10)
```
We have a lot of points in U. Unbalanced dataset. Later for modeling we will create one dataset that combines A and B, and C and D. 

```{r}
data.2 <- melt(data.L[, c("Used", "Ave_Wet", "Prec_Tree", "L.dist2build")], id.vars="Used")
ggplot(data.2, aes(factor(Used), y = value, fill=factor(Used))) +
    geom_boxplot() +
    facet_wrap(~variable, scales="free_y")

```
Super clear that they pick high tree precentage area. slightly far away from building, almost no difference in age and ave wet. We expect precentage tree will play an important role.

```{r scaling, include = false}
# # scaling numeric variables by deviding two standard deviations for binary predictors
# # http://www.stat.columbia.edu/~gelman/research/published/standardizing7.pdf
# data.scaled <- data
# data.scaled$dist2build <- log(data.scaled$dist2build + 1)
# data.scaled[,5:8] <- sapply(data.scaled[,5:8], rescale, binary.inputs = "full")
# #data.scaled$Ave_Wet <- sqrt(data.scaled$Ave_Wet)
# #data.scaled$Prec_Tree <- sqrt(data.scaled$Prec_Tree)  # issue: take sqrt creates lots of NA 
# ggpairs(data.scaled[, c("Age", "Ave_Wet", "Prec_Tree", "dist2build")])
```


## fitting and diagnostic clogit
```{r fitting round 1}
# full model
m.0 <- clogit(Used ~ Fire_Cat + Prec_Tree + Veg_Class + Ave_Wet + L.dist2build + strata(DenID), data = data.L, method='efron')
summary(m.0)
# # if combine fire cat 
# data.LC <- data.L %>% mutate(Fire_Cat_C = ifelse (Fire_Cat == "A" | Fire_Cat == "B", "AB", 
#                              ifelse (Fire_Cat == "U", "U", "CD")))
# data.LC$Fire_Cat_C <- factor(data.LC$Fire_Cat_C, levels = c("AB", "CD", "U"))
# m.0c <- clogit(Used ~ Fire_Cat_C + Prec_Tree + Veg_Class + Ave_Wet + L.dist2build + strata(DenID), data = data.LC, method='efron')
# summary(m.0c)
# # combining class attenuate impacts of fire class C... decide to go back to not combined classes

m.1 <- clogit(Used ~ Fire_Cat + Prec_Tree + Veg_Class + L.dist2build + strata(DenID), data = data.L, method='efron')
m.2 <- clogit(Used ~ Fire_Cat + Prec_Tree  + Veg_Class+ Ave_Wet + strata(DenID), data = data.L, method='efron')
m.3 <- clogit(Used ~ Fire_Cat + Veg_Class + Ave_Wet + L.dist2build + strata(DenID), data = data.L, method='efron')
m.4 <- clogit(Used ~ Fire_Cat + Prec_Tree + Ave_Wet + L.dist2build + strata(DenID), data = data.L, method='efron')
AICc(m.0, m.1,m.2,m.3,m.4)
```
The term exp(coef) is giving the odds ratio for an increase of 1 unit in the independent variable. We drop vegclass here.

```{r fitting round 2}
m.10 <- clogit(Used ~ Fire_Cat + Prec_Tree + Ave_Wet + L.dist2build + strata(DenID), data = data.L, method='efron')
m.11 <- clogit(Used ~ Fire_Cat + Prec_Tree + L.dist2build + strata(DenID), data = data.L, method='efron')
m.12 <- clogit(Used ~ Fire_Cat + Prec_Tree + Ave_Wet + strata(DenID), data = data.L, method='efron')
m.13 <- clogit(Used ~ Fire_Cat  + Ave_Wet + L.dist2build + strata(DenID), data = data.L, method='efron')
AICc(m.10, m.11, m.12, m.13)
```
Drop ave_wet.

```{r fitting round 3}
m.100 <- clogit(Used ~ Fire_Cat + Prec_Tree + L.dist2build + strata(DenID), data = data.L, method='efron')
m.101 <-  clogit(Used ~ Fire_Cat + Prec_Tree + strata(DenID), data = data.L, method='efron')
m.102 <- clogit(Used ~ Fire_Cat + L.dist2build + strata(DenID), data = data.L, method='efron')
AICc(m.100, m.101, m.102)
```
Best model is m.100. 

```{r clogitL1 validation, include = false}
m.100c <- clogitL1( y = data.L$Used, x = cbind(data.L$Fire_Cat, data.L$Prec_Tree, data.L$L.dist2build), strata = data.L$DenID)
plot(m.100c, logX = TRUE)
clcvObj = cv.clogitL1(m.100c, 5)
plot(clcvObj)
```






```{r confidence interval} 
# this confident interval is calculated based on maximum likihood
# note that the numbers here are log-transformed
co.table <- cbind(OR = coef(m.2), confint(m.2))
co.df <- data.frame(variable = row.names(co.table), estimate = co.table[1:nrow(co.table), 1], LL = co.table[1:nrow(co.table), 2], UL =  co.table[1:nrow(co.table), 3])
co.df$variable <- as.character(co.df$variable)

ggplot(co.df, aes(y=estimate, x=variable, ymin=LL, ymax=UL)) + geom_pointrange() + coord_flip()
```
For every unit increase in tree percent, the *log odds* of den presence increase for 1.22. For fire, change from category A to B, the *log odds* for den presence increase for 5.1


We can test for an overall effect of rank using the wald.test function of the aod library. The order in which the coefficients are given in the table of coefficients is the same as the order of the terms in the model. This is important because the wald.test function refers to the coefficients by their order in the model. We use the wald.test function.

``` {r overall effect}
wald.test(b = coef(m.2), Sigma = vcov(m.2), Terms = 1:5)
```
The chi-squared test statistic of 308.8, with 5 degrees of freedom is associated with a p-value of 0.00 indicating that the overall effect of rank is statistically significant.


We can also test additional hypotheses about the differences in the coefficients for the different levels of rank. To contrast these two terms, we multiply one of them by 1, and the other by -1. The other terms in the model are not involved in the test, so they are multiplied by 0. The second line of code below uses L=l to tell R that we wish to base the test on the vector l (rather than using the Terms option as we did above).
``` {r additional hypotheses}
l <- cbind(1, -1, 0, 0, 0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0)
wald.test(b = coef(m.2), Sigma = vcov(m.2), L = l)

l <- cbind(0, 0, 0, 1, -1 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0,0 )
wald.test(b = coef(m.2), Sigma = vcov(m.2), L = l)
```
It looks like only A is significantly different from other fire cat. 

Now exponentiate the coefficients and interpret them as odds-ratios. 
```{r}
### odds ratios and 95% CI
exp(cbind(OR = coef(m.2), confint(m.2)))
```
For every unit increase in tree percent, the odds of den presence increase for 6.756 (note that one unit is like from 0 precent to 100% tree. but in reality it is limited from 0 to 1). For fire, change from category A to B, the odds for den presence increase for 1.131. Or, when holding all other variables as fixed, Fire Cat B is 13% more likely to have dens then newly burned area. 



Create a table to plot predict probabilities varying percent tree
``` {r predict - tree prec by fire cat}
newdata <- with(data.scaled[4:9], data.frame(Fire_Cat = factor(rep(c("A", "B", "C", "D", "U"), each = 100)),
                                                          Age = mean(data.scaled$Age),
                                                          Ave_Wet = mean(data.scaled$Ave_Wet), 
                                                          Prec_Tree = rep(seq(from = -1, to = 1, length.out = 100), 5), 
                                                          dist2build = mean(data.scaled$dist2build),
                                                          Veg_Class = "Other"))

newdata <- cbind(newdata, predict(m.2, newdata = newdata, type = "link", se = TRUE))
newdata <- within(newdata, {
  PredictedProb <- plogis(fit)
  LL <- plogis(fit - (1.96 * se.fit))
  UL <- plogis(fit + (1.96 * se.fit))
})

p.1 <- ggplot(newdata, aes(x = Prec_Tree, y = PredictedProb)) + geom_ribbon(aes(ymin = LL,
    ymax = UL, fill = Fire_Cat), alpha = 0.2) + geom_line(aes(colour = Fire_Cat),
    size = 1)
p.1
```

``` {r fire cat}
newdata2 <- with(data.scaled[4:9], data.frame(Fire_Cat = factor(rep(c("A", "B", "C", "D", "U"), each = 5)),
                                                          Age = mean(data.scaled$Age),
                                                          Ave_Wet = mean(data.scaled$Ave_Wet), 
                                                          Prec_Tree = mean(data.scaled$Prec_Tree), 
                                                          dist2build = mean(data.scaled$dist2build),
                                                          Veg_Class = rep(c("Other", "Marsh-Shrub-Swamp", "Prairie-Grassland", "Upland Forest", "Wetland Forest"), 5)))

newdata2 <- cbind(newdata2, predict(m.2, newdata = newdata2, type = "link", se = TRUE))
newdata2 <- within(newdata2, {
  PredictedProb <- plogis(fit)
  LL <- plogis(fit - (1.96 * se.fit))
  UL <- plogis(fit + (1.96 * se.fit))
})

p.2 <- ggplot(newdata2, aes(x = Fire_Cat, y = PredictedProb, colour = Veg_Class)) + 
  geom_point() + 
  geom_linerange(aes(ymin = LL, ymax = UL))
p.2
```
"Other" is significantly higher than other classes. Need to further tease apart different classes.